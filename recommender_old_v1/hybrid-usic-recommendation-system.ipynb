{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid music recommender system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-29T05:16:51.526986Z",
     "iopub.status.busy": "2025-03-29T05:16:51.526695Z",
     "iopub.status.idle": "2025-03-29T05:16:51.531091Z",
     "shell.execute_reply": "2025-03-29T05:16:51.530209Z",
     "shell.execute_reply.started": "2025-03-29T05:16:51.526967Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T05:16:52.299429Z",
     "iopub.status.busy": "2025-03-29T05:16:52.299129Z",
     "iopub.status.idle": "2025-03-29T05:16:57.124679Z",
     "shell.execute_reply": "2025-03-29T05:16:57.123939Z",
     "shell.execute_reply.started": "2025-03-29T05:16:52.299411Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "users_history = pd.read_csv(\n",
    "    \"/kaggle/input/million-song-dataset-spotify-lastfm/User Listening History.csv\"\n",
    ")\n",
    "\n",
    "music_info = pd.read_csv(\n",
    "    \"/kaggle/input/million-song-dataset-spotify-lastfm/Music Info.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T05:16:57.126052Z",
     "iopub.status.busy": "2025-03-29T05:16:57.125869Z",
     "iopub.status.idle": "2025-03-29T05:16:57.131270Z",
     "shell.execute_reply": "2025-03-29T05:16:57.130210Z",
     "shell.execute_reply.started": "2025-03-29T05:16:57.126036Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "users_history.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T05:16:57.132318Z",
     "iopub.status.busy": "2025-03-29T05:16:57.132150Z",
     "iopub.status.idle": "2025-03-29T05:16:57.142033Z",
     "shell.execute_reply": "2025-03-29T05:16:57.141226Z",
     "shell.execute_reply.started": "2025-03-29T05:16:57.132303Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "music_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T05:16:57.316979Z",
     "iopub.status.busy": "2025-03-29T05:16:57.316340Z",
     "iopub.status.idle": "2025-03-29T05:16:57.360289Z",
     "shell.execute_reply": "2025-03-29T05:16:57.359479Z",
     "shell.execute_reply.started": "2025-03-29T05:16:57.316957Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "music_info.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T05:16:58.364822Z",
     "iopub.status.busy": "2025-03-29T05:16:58.364517Z",
     "iopub.status.idle": "2025-03-29T05:16:58.375401Z",
     "shell.execute_reply": "2025-03-29T05:16:58.374517Z",
     "shell.execute_reply.started": "2025-03-29T05:16:58.364799Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "users_history[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T05:17:03.749228Z",
     "iopub.status.busy": "2025-03-29T05:17:03.748983Z",
     "iopub.status.idle": "2025-03-29T05:17:03.769645Z",
     "shell.execute_reply": "2025-03-29T05:17:03.768757Z",
     "shell.execute_reply.started": "2025-03-29T05:17:03.749211Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "music_info[1:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing synthetic data generation with spotify demographic based info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: First cluster the songs based on audio features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select audio features for clustering\n",
    "audio_features = [\n",
    "    \"danceability\",\n",
    "    \"energy\",\n",
    "    \"key\",\n",
    "    \"loudness\",\n",
    "    \"mode\",\n",
    "    \"speechiness\",\n",
    "    \"acousticness\",\n",
    "    \"instrumentalness\",\n",
    "    \"liveness\",\n",
    "    \"valence\",\n",
    "    \"tempo\",\n",
    "]\n",
    "\n",
    "\n",
    "# Extract genre information\n",
    "def extract_main_genres(tag_string):\n",
    "    if pd.isna(tag_string):\n",
    "        return []\n",
    "\n",
    "    tags = str(tag_string).lower().split(\",\")\n",
    "    genres = []\n",
    "    main_genres = [\n",
    "        \"rock\",\n",
    "        \"pop\",\n",
    "        \"hip hop\",\n",
    "        \"rap\",\n",
    "        \"electronic\",\n",
    "        \"dance\",\n",
    "        \"jazz\",\n",
    "        \"classical\",\n",
    "        \"r&b\",\n",
    "        \"country\",\n",
    "        \"indie\",\n",
    "        \"folk\",\n",
    "    ]\n",
    "\n",
    "    for genre in main_genres:\n",
    "        if any(genre in tag for tag in tags):\n",
    "            genres.append(genre)\n",
    "\n",
    "    return genres if genres else [\"other\"]\n",
    "\n",
    "\n",
    "# Add genre features to music_info\n",
    "music_info[\"main_genres\"] = music_info[\"tags\"].apply(extract_main_genres)\n",
    "\n",
    "# One-hot encode main genres\n",
    "for genre in [\n",
    "    \"rock\",\n",
    "    \"pop\",\n",
    "    \"hip hop\",\n",
    "    \"rap\",\n",
    "    \"electronic\",\n",
    "    \"dance\",\n",
    "    \"jazz\",\n",
    "    \"classical\",\n",
    "    \"r&b\",\n",
    "    \"country\",\n",
    "    \"indie\",\n",
    "    \"folk\",\n",
    "    \"other\",\n",
    "]:\n",
    "    music_info[f\"genre_{genre}\"] = music_info[\"main_genres\"].apply(\n",
    "        lambda x: 1 if genre in x else 0\n",
    "    )\n",
    "\n",
    "# Combine audio features and genre information for clustering\n",
    "genre_features = [col for col in music_info.columns if col.startswith(\"genre_\")]\n",
    "music_features_df = music_info[[\"track_id\"] + audio_features + genre_features].copy()\n",
    "\n",
    "# Normalize features for song clustering\n",
    "scaler = StandardScaler()\n",
    "features_to_scale = audio_features + genre_features\n",
    "music_features_df_scaled = music_features_df.copy()\n",
    "music_features_df_scaled[features_to_scale] = scaler.fit_transform(\n",
    "    music_features_df[features_to_scale]\n",
    ")\n",
    "\n",
    "# Cluster songs (we'll create 20 song clusters)\n",
    "n_song_clusters = 20\n",
    "song_kmeans = KMeans(n_clusters=n_song_clusters, random_state=42, n_init=10)\n",
    "music_features_df_scaled[\"song_cluster\"] = song_kmeans.fit_predict(\n",
    "    music_features_df_scaled[features_to_scale]\n",
    ")\n",
    "song_clusters = music_features_df_scaled[[\"track_id\", \"song_cluster\"]]\n",
    "\n",
    "# Analyze the song clusters to understand what each represents\n",
    "cluster_profile = []\n",
    "for cluster_id in range(n_song_clusters):\n",
    "    cluster_tracks = music_features_df[\n",
    "        music_features_df_scaled[\"song_cluster\"] == cluster_id\n",
    "    ]\n",
    "\n",
    "    # Get average audio features\n",
    "    avg_features = cluster_tracks[audio_features].mean().to_dict()\n",
    "\n",
    "    # Get most common genres\n",
    "    genre_counts = cluster_tracks[genre_features].sum()\n",
    "    top_genres = genre_counts.nlargest(3).index.tolist()\n",
    "    top_genres = [g.replace(\"genre_\", \"\") for g in top_genres]\n",
    "\n",
    "    cluster_profile.append(\n",
    "        {\n",
    "            \"cluster_id\": cluster_id,\n",
    "            \"size\": len(cluster_tracks),\n",
    "            \"top_genres\": top_genres,\n",
    "            **avg_features,\n",
    "        }\n",
    "    )\n",
    "\n",
    "song_cluster_profile = pd.DataFrame(cluster_profile)\n",
    "print(\"Song Cluster Profiles:\")\n",
    "print(\n",
    "    song_cluster_profile[\n",
    "        [\"cluster_id\", \"size\", \"top_genres\", \"danceability\", \"energy\", \"valence\"]\n",
    "    ].head()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create user preference distributions across song clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_song_clusters = users_history.merge(song_clusters, on=\"track_id\")\n",
    "\n",
    "# Create distribution of song clusters for each user (weighted by playcount)\n",
    "user_cluster_distributions = (\n",
    "    user_song_clusters.groupby([\"user_id\", \"song_cluster\"])[\"playcount\"]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "total_plays = (\n",
    "    user_cluster_distributions.groupby(\"user_id\")[\"playcount\"].sum().reset_index()\n",
    ")\n",
    "total_plays.rename(columns={\"playcount\": \"total_playcount\"}, inplace=True)\n",
    "user_cluster_distributions = user_cluster_distributions.merge(total_plays, on=\"user_id\")\n",
    "user_cluster_distributions[\"percentage\"] = (\n",
    "    user_cluster_distributions[\"playcount\"]\n",
    "    / user_cluster_distributions[\"total_playcount\"]\n",
    ") * 100\n",
    "\n",
    "# Create a pivot table to get user distribution vectors\n",
    "user_vectors = user_cluster_distributions.pivot_table(\n",
    "    index=\"user_id\", columns=\"song_cluster\", values=\"percentage\", fill_value=0\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Calculate diversity metrics for each user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_diversity(row):\n",
    "    # Convert percentages to probabilities\n",
    "    probs = (\n",
    "        np.array([float(x) for x in row[1:]], dtype=float) / 100.0\n",
    "    )  # Exclude user_id column and convert to numpy array\n",
    "    probs = probs[probs > 0]  # Only consider non-zero probabilities\n",
    "\n",
    "    # Shannon entropy as diversity measure\n",
    "    if len(probs) > 0:\n",
    "        entropy = -np.sum(\n",
    "            probs * np.log2(probs + np.finfo(float).eps)\n",
    "        )  # Add small epsilon to avoid log(0)\n",
    "        return entropy\n",
    "    return 0\n",
    "\n",
    "\n",
    "# Calculate listening diversity for each user\n",
    "user_vectors[\"listening_diversity\"] = user_vectors.apply(calculate_diversity, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Cluster users based on their listening distributions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_feature_cols = [col for col in user_vectors.columns if isinstance(col, int)]\n",
    "user_scaler = StandardScaler()\n",
    "user_scaled_features = user_scaler.fit_transform(user_vectors[user_feature_cols])\n",
    "\n",
    "# We'll create 8 user clusters\n",
    "n_user_clusters = 8\n",
    "user_kmeans = KMeans(n_clusters=n_user_clusters, random_state=42, n_init=10)\n",
    "user_vectors[\"user_cluster\"] = user_kmeans.fit_predict(user_scaled_features)\n",
    "\n",
    "# Analyze user clusters to understand what each represents\n",
    "user_cluster_profiles = []\n",
    "for cluster_id in range(n_user_clusters):\n",
    "    cluster_users = user_vectors[user_vectors[\"user_cluster\"] == cluster_id]\n",
    "\n",
    "    # Get average distribution across song clusters\n",
    "    avg_distribution = cluster_users[user_feature_cols].mean().to_dict()\n",
    "\n",
    "    # Find top song clusters for this user cluster\n",
    "    top_3_song_clusters = sorted(\n",
    "        avg_distribution.items(), key=lambda x: x[1], reverse=True\n",
    "    )[:3]\n",
    "\n",
    "    # Map those to the song cluster profiles\n",
    "    top_genres = []\n",
    "    for song_cluster, percentage in top_3_song_clusters:\n",
    "        top_genres.extend(\n",
    "            song_cluster_profile.loc[\n",
    "                song_cluster_profile[\"cluster_id\"] == song_cluster, \"top_genres\"\n",
    "            ].iloc[0]\n",
    "        )\n",
    "\n",
    "    # Average diversity\n",
    "    avg_diversity = cluster_users[\"listening_diversity\"].mean()\n",
    "\n",
    "    user_cluster_profiles.append(\n",
    "        {\n",
    "            \"user_cluster_id\": cluster_id,\n",
    "            \"size\": len(cluster_users),\n",
    "            \"top_song_clusters\": [sc[0] for sc in top_3_song_clusters],\n",
    "            \"top_genres\": list(set(top_genres)),\n",
    "            \"avg_diversity\": avg_diversity,\n",
    "        }\n",
    "    )\n",
    "\n",
    "user_cluster_profile_df = pd.DataFrame(user_cluster_profiles)\n",
    "print(\"\\nUser Cluster Profiles:\")\n",
    "print(user_cluster_profile_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Assign demographics based on user clusters and known Spotify demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define demographic distributions\n",
    "age_groups = [\n",
    "    (18, 24),  # 31.51%\n",
    "    (25, 34),  # 31.41%\n",
    "    (35, 44),  # ~15%\n",
    "    (45, 54),  # ~10%\n",
    "    (55, 64),  # ~8%\n",
    "    (65, 100),  # ~4%\n",
    "]\n",
    "\n",
    "# Base probabilities from Spotify data\n",
    "base_age_probabilities = [0.3151, 0.3141, 0.15, 0.10, 0.08, 0.04]\n",
    "base_gender_probabilities = {\"Female\": 0.56, \"Male\": 0.44}\n",
    "base_region_probabilities = {\n",
    "    \"Europe\": 0.27,\n",
    "    \"North America\": 0.28,\n",
    "    \"Latin America\": 0.22,\n",
    "    \"Rest of World\": 0.23,\n",
    "}\n",
    "\n",
    "\n",
    "# Adjust demographics based on user cluster characteristics\n",
    "# This is where we encode the correlations between music taste and demographics\n",
    "def adjust_demographics_by_genres(cluster_profile):\n",
    "    \"\"\"Adjust demographic probabilities based on genre preferences\"\"\"\n",
    "    age_adj = base_age_probabilities.copy()\n",
    "    gender_adj = base_gender_probabilities.copy()\n",
    "    region_adj = base_region_probabilities.copy()\n",
    "\n",
    "    # These adjustments are based on research about music preferences by demographic\n",
    "    # Implement correlations between genres and demographics\n",
    "    genres = cluster_profile[\"top_genres\"]\n",
    "\n",
    "    # Age correlations\n",
    "    if any(g in genres for g in [\"hip hop\", \"rap\", \"dance\", \"electronic\"]):\n",
    "        # Increase younger age groups probability\n",
    "        age_adj[0] *= 1.3  # 18-24\n",
    "        age_adj[1] *= 1.2  # 25-34\n",
    "\n",
    "    if any(g in genres for g in [\"rock\", \"indie\", \"alternative\"]):\n",
    "        # Slight increase in middle age groups\n",
    "        age_adj[1] *= 1.15  # 25-34\n",
    "        age_adj[2] *= 1.2  # 35-44\n",
    "\n",
    "    if any(g in genres for g in [\"jazz\", \"classical\", \"folk\"]):\n",
    "        # Increase older age groups probability\n",
    "        age_adj[3] *= 1.3  # 45-54\n",
    "        age_adj[4] *= 1.3  # 55-64\n",
    "        age_adj[5] *= 1.5  # 65+\n",
    "\n",
    "    # Gender correlations\n",
    "    if any(g in genres for g in [\"hip hop\", \"rap\", \"rock\"]):\n",
    "        gender_adj[\"Male\"] *= 1.15\n",
    "\n",
    "    if any(g in genres for g in [\"pop\", \"dance\"]):\n",
    "        gender_adj[\"Female\"] *= 1.1\n",
    "\n",
    "    # Region correlations\n",
    "    if any(g in genres for g in [\"hip hop\", \"rap\", \"r&b\"]):\n",
    "        region_adj[\"North America\"] *= 1.2\n",
    "\n",
    "    if any(g in genres for g in [\"electronic\", \"dance\"]):\n",
    "        region_adj[\"Europe\"] *= 1.2\n",
    "\n",
    "    if any(g in genres for g in [\"latin\"]):\n",
    "        region_adj[\"Latin America\"] *= 1.5\n",
    "\n",
    "    # Also consider diversity factor (high diversity = different pattern)\n",
    "    diversity = cluster_profile[\"avg_diversity\"]\n",
    "    if diversity > 2.5:  # High diversity\n",
    "        # More balanced across demographics\n",
    "        age_adj = [0.25, 0.25, 0.15, 0.15, 0.1, 0.1]\n",
    "\n",
    "    # Normalize to ensure probabilities sum to 1\n",
    "    age_adj = np.array(age_adj)\n",
    "    age_adj = age_adj / age_adj.sum()\n",
    "\n",
    "    gender_values = np.array(list(gender_adj.values()))\n",
    "    gender_values = gender_values / gender_values.sum()\n",
    "    gender_adj = {k: gender_values[i] for i, k in enumerate(gender_adj.keys())}\n",
    "\n",
    "    region_values = np.array(list(region_adj.values()))\n",
    "    region_values = region_values / region_values.sum()\n",
    "    region_adj = {k: region_values[i] for i, k in enumerate(region_adj.keys())}\n",
    "\n",
    "    return age_adj, gender_adj, region_adj\n",
    "\n",
    "\n",
    "# Create final user demographics\n",
    "countries_by_region = {\n",
    "    \"Europe\": [\n",
    "        \"UK\",\n",
    "        \"Germany\",\n",
    "        \"France\",\n",
    "        \"Spain\",\n",
    "        \"Italy\",\n",
    "        \"Sweden\",\n",
    "        \"Netherlands\",\n",
    "        \"Poland\",\n",
    "    ],\n",
    "    \"North America\": [\"USA\", \"Canada\"],\n",
    "    \"Latin America\": [\"Brazil\", \"Mexico\", \"Argentina\", \"Colombia\", \"Chile\"],\n",
    "    \"Rest of World\": [\n",
    "        \"Japan\",\n",
    "        \"Australia\",\n",
    "        \"India\",\n",
    "        \"South Korea\",\n",
    "        \"South Africa\",\n",
    "        \"UAE\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "user_demographics = []\n",
    "\n",
    "for cluster_id, cluster_profile in user_cluster_profile_df.iterrows():\n",
    "    # Get users in this cluster\n",
    "    cluster_users = user_vectors[\n",
    "        user_vectors[\"user_cluster\"] == cluster_profile[\"user_cluster_id\"]\n",
    "    ][\"user_id\"].values\n",
    "    n_cluster_users = len(cluster_users)\n",
    "\n",
    "    # Adjust demographic probabilities based on cluster profile\n",
    "    age_probs, gender_probs, region_probs = adjust_demographics_by_genres(\n",
    "        cluster_profile\n",
    "    )\n",
    "\n",
    "    # Assign demographics to each user in the cluster\n",
    "    for user_id in cluster_users:\n",
    "        # Age\n",
    "        age_group_idx = np.random.choice(len(age_groups), p=age_probs)\n",
    "        age_range = age_groups[age_group_idx]\n",
    "        age = np.random.randint(age_range[0], age_range[1] + 1)\n",
    "\n",
    "        # Gender\n",
    "        gender = np.random.choice(\n",
    "            list(gender_probs.keys()), p=list(gender_probs.values())\n",
    "        )\n",
    "\n",
    "        # Region\n",
    "        region = np.random.choice(\n",
    "            list(region_probs.keys()), p=list(region_probs.values())\n",
    "        )\n",
    "\n",
    "        # Country within region\n",
    "        country = np.random.choice(countries_by_region[region])\n",
    "\n",
    "        # Listening hours (correlated with age and gender)\n",
    "        base_hours = 0\n",
    "        if age < 25:\n",
    "            base_hours = 25 + np.random.normal(5, 3)\n",
    "        elif age < 35:\n",
    "            base_hours = 20 + np.random.normal(4, 3)\n",
    "        elif age < 45:\n",
    "            base_hours = 15 + np.random.normal(5, 2)\n",
    "        else:\n",
    "            base_hours = 10 + np.random.normal(5, 2)\n",
    "\n",
    "        # Gen Z women tend to listen more (30 hrs vs 24 hrs for men)\n",
    "        if age < 25 and gender == \"Female\":\n",
    "            base_hours *= 1.2\n",
    "\n",
    "        monthly_hours = max(5, min(60, base_hours))  # Cap between 5 and 60 hours\n",
    "\n",
    "        # Get diversity from user vectors\n",
    "        user_diversity = user_vectors.loc[\n",
    "            user_vectors[\"user_id\"] == user_id, \"listening_diversity\"\n",
    "        ].values[0]\n",
    "\n",
    "        user_demographics.append(\n",
    "            {\n",
    "                \"user_id\": user_id,\n",
    "                \"age\": age,\n",
    "                \"gender\": gender,\n",
    "                \"region\": region,\n",
    "                \"country\": country,\n",
    "                \"monthly_hours\": monthly_hours,\n",
    "                \"user_cluster\": cluster_profile[\"user_cluster_id\"],\n",
    "                \"listening_diversity\": user_diversity,\n",
    "                \"top_genres\": cluster_profile[\"top_genres\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "# Create final demographics dataframe\n",
    "user_demographics_df = pd.DataFrame(user_demographics)\n",
    "\n",
    "# Generate some visualizations for demographic distribution\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Age distribution\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.histplot(user_demographics_df[\"age\"], bins=20)\n",
    "plt.title(\"Age Distribution\")\n",
    "\n",
    "# Gender distribution\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.countplot(x=\"gender\", data=user_demographics_df)\n",
    "plt.title(\"Gender Distribution\")\n",
    "\n",
    "# Region distribution\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.countplot(y=\"region\", data=user_demographics_df)\n",
    "plt.title(\"Region Distribution\")\n",
    "\n",
    "# Listening hours by age group\n",
    "plt.subplot(2, 2, 4)\n",
    "user_demographics_df[\"age_group\"] = pd.cut(\n",
    "    user_demographics_df[\"age\"],\n",
    "    [18, 24, 34, 44, 54, 64, 100],\n",
    "    labels=[\"18-24\", \"25-34\", \"35-44\", \"45-54\", \"55-64\", \"65+\"],\n",
    ")\n",
    "sns.boxplot(x=\"age_group\", y=\"monthly_hours\", data=user_demographics_df)\n",
    "plt.title(\"Listening Hours by Age Group\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"demographic_distributions.png\")\n",
    "\n",
    "# Save the final synthetic demographics\n",
    "user_demographics_df.to_csv(\"rich_synthetic_user_demographics.csv\", index=False)\n",
    "\n",
    "print(f\"\\nCreated rich synthetic demographics for {len(user_demographics_df)} users\")\n",
    "print(user_demographics_df.head())\n",
    "\n",
    "# Additional analysis - show listening patterns by demographic\n",
    "print(\"\\nAverage listening diversity by age group:\")\n",
    "print(user_demographics_df.groupby(\"age_group\")[\"listening_diversity\"].mean())\n",
    "\n",
    "print(\"\\nTop user clusters by gender:\")\n",
    "print(\n",
    "    user_demographics_df.groupby([\"gender\", \"user_cluster\"])\n",
    "    .size()\n",
    "    .reset_index()\n",
    "    .rename(columns={0: \"count\"})\n",
    "    .sort_values([\"gender\", \"count\"], ascending=[True, False])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping the songs of each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T08:20:04.194841Z",
     "iopub.status.busy": "2025-03-27T08:20:04.194460Z",
     "iopub.status.idle": "2025-03-27T08:21:26.965709Z",
     "shell.execute_reply": "2025-03-27T08:21:26.964795Z",
     "shell.execute_reply.started": "2025-03-27T08:20:04.194811Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "user_song_list = users_history.groupby('user_id', observed=True)[['track_id', 'playcount']].apply(lambda x: list(zip(x['track_id'], x['playcount']))).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T21:48:37.187643Z",
     "iopub.status.busy": "2025-03-26T21:48:37.187345Z",
     "iopub.status.idle": "2025-03-26T21:48:40.311854Z",
     "shell.execute_reply": "2025-03-26T21:48:40.310879Z",
     "shell.execute_reply.started": "2025-03-26T21:48:37.187611Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dict(list(user_song_list.items())[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Removing the users who have listened to less than 50 songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T21:48:40.314017Z",
     "iopub.status.busy": "2025-03-26T21:48:40.313584Z",
     "iopub.status.idle": "2025-03-26T21:48:41.195088Z",
     "shell.execute_reply": "2025-03-26T21:48:41.194152Z",
     "shell.execute_reply.started": "2025-03-26T21:48:40.313985Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "user_song_list = {user: songs for user, songs in user_song_list.items() if len(songs) >= 50}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T21:48:41.196902Z",
     "iopub.status.busy": "2025-03-26T21:48:41.196699Z",
     "iopub.status.idle": "2025-03-26T21:48:41.213016Z",
     "shell.execute_reply": "2025-03-26T21:48:41.212154Z",
     "shell.execute_reply.started": "2025-03-26T21:48:41.196885Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dict(list(user_song_list.items())[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T21:48:41.214208Z",
     "iopub.status.busy": "2025-03-26T21:48:41.213965Z",
     "iopub.status.idle": "2025-03-26T21:48:41.231270Z",
     "shell.execute_reply": "2025-03-26T21:48:41.230241Z",
     "shell.execute_reply.started": "2025-03-26T21:48:41.214188Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "len(user_song_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing the data related to users that have listened to less than 50 songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T21:49:30.356050Z",
     "iopub.status.busy": "2025-03-26T21:49:30.355774Z",
     "iopub.status.idle": "2025-03-26T21:49:31.068766Z",
     "shell.execute_reply": "2025-03-26T21:49:31.067453Z",
     "shell.execute_reply.started": "2025-03-26T21:49:30.356033Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "users_history = users_history[users_history['user_id'].isin(user_song_list.keys())] \n",
    "users_history.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T21:21:46.979809Z",
     "iopub.status.busy": "2024-06-08T21:21:46.979474Z",
     "iopub.status.idle": "2024-06-08T21:21:46.985442Z",
     "shell.execute_reply": "2024-06-08T21:21:46.984379Z",
     "shell.execute_reply.started": "2024-06-08T21:21:46.979773Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import csr_matrix,coo_matrix\n",
    "from annoy import AnnoyIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the columns that represent the numerical values for each song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T21:21:47.376205Z",
     "iopub.status.busy": "2024-06-08T21:21:47.375846Z",
     "iopub.status.idle": "2024-06-08T21:21:47.38269Z",
     "shell.execute_reply": "2024-06-08T21:21:47.381677Z",
     "shell.execute_reply.started": "2024-06-08T21:21:47.376178Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "feature_columns = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', \n",
    "                   'instrumentalness', 'liveness', 'valence', 'tempo']\n",
    "#numerical_features = music_info[feature_columns].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T21:21:47.384324Z",
     "iopub.status.busy": "2024-06-08T21:21:47.384017Z",
     "iopub.status.idle": "2024-06-08T21:21:47.407872Z",
     "shell.execute_reply": "2024-06-08T21:21:47.406343Z",
     "shell.execute_reply.started": "2024-06-08T21:21:47.384294Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "normalized_numerical_features = scaler.fit_transform(music_info[feature_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the annoy index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T21:21:47.410692Z",
     "iopub.status.busy": "2024-06-08T21:21:47.410238Z",
     "iopub.status.idle": "2024-06-08T21:21:49.449548Z",
     "shell.execute_reply": "2024-06-08T21:21:49.448255Z",
     "shell.execute_reply.started": "2024-06-08T21:21:47.410652Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "feature_length = normalized_numerical_features.shape[1]\n",
    "annoy_index = AnnoyIndex(feature_length, 'angular')\n",
    "\n",
    "for idx, vector in enumerate(normalized_numerical_features):\n",
    "    annoy_index.add_item(idx, vector)\n",
    "\n",
    "annoy_index.build(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The 6 most close songs to the first song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T21:21:49.452122Z",
     "iopub.status.busy": "2024-06-08T21:21:49.451647Z",
     "iopub.status.idle": "2024-06-08T21:21:49.460351Z",
     "shell.execute_reply": "2024-06-08T21:21:49.459232Z",
     "shell.execute_reply.started": "2024-06-08T21:21:49.45208Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "annoy_index.get_nns_by_item(0, 7)[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T21:21:49.462467Z",
     "iopub.status.busy": "2024-06-08T21:21:49.462138Z",
     "iopub.status.idle": "2024-06-08T21:21:49.981976Z",
     "shell.execute_reply": "2024-06-08T21:21:49.980933Z",
     "shell.execute_reply.started": "2024-06-08T21:21:49.462434Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(users_history, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating mappings so we can find a song_id by index and vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T21:21:49.983822Z",
     "iopub.status.busy": "2024-06-08T21:21:49.983488Z",
     "iopub.status.idle": "2024-06-08T21:21:51.132538Z",
     "shell.execute_reply": "2024-06-08T21:21:51.131394Z",
     "shell.execute_reply.started": "2024-06-08T21:21:49.983794Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# For collaborative filtering (using users_history)\n",
    "train['user_id'] = train['user_id'].astype('category')\n",
    "train['track_id'] = train['track_id'].astype('category')\n",
    "\n",
    "# Create mappings for user_id and track_id\n",
    "cf_user_id_mapping = dict(enumerate(train['user_id'].cat.categories))\n",
    "cf_track_id_mapping = dict(enumerate(train['track_id'].cat.categories))\n",
    "cf_user_id_reverse_mapping = {v: k for k, v in cf_user_id_mapping.items()}\n",
    "cf_track_id_reverse_mapping = {v: k for k, v in cf_track_id_mapping.items()}\n",
    "\n",
    "# For content-based filtering (using music_info)\n",
    "music_info['track_id'] = music_info['track_id'].astype('category')\n",
    "\n",
    "cb_track_id_mapping = dict(enumerate(music_info['track_id'].cat.categories))\n",
    "cb_track_id_reverse_mapping = {v: k for k, v in cb_track_id_mapping.items()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T21:21:51.134166Z",
     "iopub.status.busy": "2024-06-08T21:21:51.133841Z",
     "iopub.status.idle": "2024-06-08T21:21:52.089598Z",
     "shell.execute_reply": "2024-06-08T21:21:52.088314Z",
     "shell.execute_reply.started": "2024-06-08T21:21:51.134139Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create Sparse User-Item Interaction Matrix\n",
    "user_item_sparse = coo_matrix((train['playcount'],\n",
    "                               (train['user_id'].cat.codes,\n",
    "                                train['track_id'].cat.codes)))\n",
    "\n",
    "# Apply SVD on the Sparse Matrix\n",
    "svd = TruncatedSVD(n_components=10, random_state=42)\n",
    "user_factors = svd.fit_transform(user_item_sparse)\n",
    "item_factors = svd.components_.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T21:21:52.092166Z",
     "iopub.status.busy": "2024-06-08T21:21:52.091269Z",
     "iopub.status.idle": "2024-06-08T21:21:52.102849Z",
     "shell.execute_reply": "2024-06-08T21:21:52.101492Z",
     "shell.execute_reply.started": "2024-06-08T21:21:52.092126Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "user_item_sparse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T21:21:52.10505Z",
     "iopub.status.busy": "2024-06-08T21:21:52.104369Z",
     "iopub.status.idle": "2024-06-08T21:21:52.123309Z",
     "shell.execute_reply": "2024-06-08T21:21:52.121916Z",
     "shell.execute_reply.started": "2024-06-08T21:21:52.105012Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def recommend_songs_hybrid(user_id, user_item_matrix, user_factors, item_factors, music_info, annoy_index, n_recommendations=5):\n",
    "    # Check if the user_id exists in the mapping\n",
    "    user_code = cf_user_id_reverse_mapping.get(user_id)\n",
    "    if user_code is None:\n",
    "        print(f\"User ID {user_id} not found in the user-item matrix.\")\n",
    "        return []\n",
    "    \n",
    "    # Collaborative Filtering Recommendations\n",
    "    cf_predictions = np.dot(user_factors[user_code, :], item_factors.T)\n",
    "    cf_indices = np.argsort(cf_predictions)[::-1]\n",
    "    cf_recommended_tracks = [cf_track_id_mapping[i] for i in cf_indices[:n_recommendations]]\n",
    "    \n",
    "    #print(f\"Collaborative Filtering Recommendations for user {user_id}: {cf_recommended_tracks}\")\n",
    "    \n",
    "    # Content-Based Filtering Recommendations\n",
    "    cb_recommended_tracks = []\n",
    "    for track in cf_recommended_tracks:\n",
    "        track_code = cb_track_id_reverse_mapping.get(track)\n",
    "        if track_code is not None:\n",
    "            similar_tracks = annoy_index.get_nns_by_item(track_code, 4)[1:]  # Get 4 similar tracks\n",
    "            for i in similar_tracks:\n",
    "                try:\n",
    "                    cb_recommended_tracks.append(cb_track_id_mapping[i])\n",
    "                except KeyError:\n",
    "                    print(f\"KeyError: Index {i} not found in cb_track_id_mapping\")\n",
    "    \n",
    "    #print(f\"Content-Based Filtering Recommendations for user {user_id}: {cb_recommended_tracks}\")\n",
    "    \n",
    "    hybrid_recommended_tracks = list(set(cf_recommended_tracks + cb_recommended_tracks))\n",
    "    \n",
    "    #print(f\"Hybrid Recommendations for user {user_id}: {hybrid_recommended_tracks}\")\n",
    "    \n",
    "    return hybrid_recommended_tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T21:21:52.125002Z",
     "iopub.status.busy": "2024-06-08T21:21:52.124661Z",
     "iopub.status.idle": "2024-06-08T21:21:52.13667Z",
     "shell.execute_reply": "2024-06-08T21:21:52.135335Z",
     "shell.execute_reply.started": "2024-06-08T21:21:52.124975Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model_hybrid_user(user, user_test_data, user_train_data, user_item_matrix, user_factors, item_factors, music_info, annoy_index, n_recommendations=5):\n",
    "    precision = 0.0\n",
    "    recall = 0.0\n",
    "    if user in user_train_data:\n",
    "            true_tracks = user_test_data[user]\n",
    "            recommended_tracks = recommend_songs_hybrid(user, user_item_matrix, user_factors, item_factors, music_info, annoy_index, n_recommendations)\n",
    "            \n",
    "            # Calculate precision and recall\n",
    "            true_positives = len(set(recommended_tracks) & set(true_tracks))\n",
    "            precision = true_positives / len(recommended_tracks) if recommended_tracks else 0\n",
    "            recall = true_positives / len(true_tracks) if true_tracks else 0\n",
    "    return precision, recall        \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T21:21:52.138592Z",
     "iopub.status.busy": "2024-06-08T21:21:52.138203Z",
     "iopub.status.idle": "2024-06-08T21:21:52.157914Z",
     "shell.execute_reply": "2024-06-08T21:21:52.156898Z",
     "shell.execute_reply.started": "2024-06-08T21:21:52.138563Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model_hybrid(user_test_data, user_train_data, user_item_matrix, user_factors, item_factors, music_info, annoy_index, n_recommendations=5):\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "\n",
    "    for user, true_tracks in user_test_data.items():\n",
    "        if user in user_train_data:\n",
    "            recommended_tracks = recommend_songs_hybrid(user, user_item_matrix, user_factors, item_factors, music_info, annoy_index, n_recommendations)\n",
    "            \n",
    "            # Calculate precision and recall\n",
    "            true_positives = len(set(recommended_tracks) & set(true_tracks))\n",
    "            precision = true_positives / len(recommended_tracks) if recommended_tracks else 0\n",
    "            recall = true_positives / len(true_tracks) if true_tracks else 0\n",
    "            \n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "    \n",
    "    avg_precision = np.mean(precisions)\n",
    "    avg_recall = np.mean(recalls)\n",
    "    \n",
    "    return avg_precision, avg_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T21:21:52.159618Z",
     "iopub.status.busy": "2024-06-08T21:21:52.159271Z",
     "iopub.status.idle": "2024-06-08T21:21:54.831108Z",
     "shell.execute_reply": "2024-06-08T21:21:54.829933Z",
     "shell.execute_reply.started": "2024-06-08T21:21:52.159591Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "user_train_data = train.groupby('user_id', observed=True)['track_id'].apply(list).to_dict()\n",
    "user_test_data = test.groupby('user_id', observed=True)['track_id'].apply(list).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T21:21:54.836293Z",
     "iopub.status.busy": "2024-06-08T21:21:54.835962Z",
     "iopub.status.idle": "2024-06-08T21:21:54.841101Z",
     "shell.execute_reply": "2024-06-08T21:21:54.840061Z",
     "shell.execute_reply.started": "2024-06-08T21:21:54.836267Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#user_train_data[\"0000f88f8d76a238c251450913b0d070e4a77d19\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T21:21:54.842536Z",
     "iopub.status.busy": "2024-06-08T21:21:54.84223Z",
     "iopub.status.idle": "2024-06-08T21:21:54.857533Z",
     "shell.execute_reply": "2024-06-08T21:21:54.856166Z",
     "shell.execute_reply.started": "2024-06-08T21:21:54.84251Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#precision, recall = evaluate_model_hybrid_user(\"0000f88f8d76a238c251450913b0d070e4a77d19\", user_test_data, user_train_data, user_item_sparse, user_factors, item_factors, music_info, annoy_index, n_recommendations=5)\n",
    "#print(f\"Average Precision: {precision}\")\n",
    "#print(f\"Average Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T21:21:54.860363Z",
     "iopub.status.busy": "2024-06-08T21:21:54.859706Z",
     "iopub.status.idle": "2024-06-08T21:21:54.872591Z",
     "shell.execute_reply": "2024-06-08T21:21:54.87145Z",
     "shell.execute_reply.started": "2024-06-08T21:21:54.860322Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#recommend_songs_hybrid(\"0000f88f8d76a238c251450913b0d070e4a77d19\", user_item_sparse, user_factors, item_factors, music_info, annoy_index, n_recommendations=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T21:21:54.87461Z",
     "iopub.status.busy": "2024-06-08T21:21:54.874189Z",
     "iopub.status.idle": "2024-06-08T21:24:57.178057Z",
     "shell.execute_reply": "2024-06-08T21:24:57.176902Z",
     "shell.execute_reply.started": "2024-06-08T21:21:54.874577Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "precision, recall = evaluate_model_hybrid(user_test_data, user_train_data, user_item_sparse, user_factors, item_factors, music_info, annoy_index, 11)\n",
    "print(f\"Average Precision: {precision}\")\n",
    "print(f\"Average Recall: {recall}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3166258,
     "sourceId": 5485048,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30715,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
